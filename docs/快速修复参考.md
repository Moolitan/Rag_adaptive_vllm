# 🚀 快速修复参考

## 已修复的关键问题

### ✅ 1. 嵌入模型配置（最重要！）

**之前的问题**:
```python
# ❌ 硬编码路径，无法移植
embedding = HuggingFaceEmbeddings(
    model_name="/mnt/Large_Language_Model_Lab_1/模型/...",
    ...
)
```

**现在的解决方案**:
```python
# ✅ 使用集中配置，自动处理
from core.config import EmbeddingConfig
embedding = EmbeddingConfig.get_embedding(device="cuda")
```

**环境变量配置（可选）**:
```bash
# 方法 1: 在 .env 文件中添加
echo 'EMBEDDING_MODEL_PATH="/your/path/to/model"' >> .env

# 方法 2: 在命令行临时设置
export EMBEDDING_MODEL_PATH="/your/path/to/model"

# 方法 3: 不设置，使用默认值或 HuggingFace Hub
# 系统会自动选择最佳选项
```

---

### ✅ 2. 正确的文件位置

| 文件 | 实际位置 |
|------|---------|
| `bench_hotpotqa_fullwiki.py` | `tests/rag_system/` ⚠️ 不在 `answer_quality/` |
| `index_hotpotqa_fullwiki.py` | `tests/data/hotpotqa/` |
| `verify_hotpotqa_setup.py` | `tests/data/hotpotqa/` |
| 嵌入模型配置 | `core/config.py` 中的 `EmbeddingConfig` |

---

### ✅ 3. 测试命令（已更新）

```bash
# vLLM 基线测试
cd tests/vllm_baseline
python test_vllm_baseline.py --context-sweep --num-requests 100

# RAG 系统性能测试
cd tests/rag_system
python system_bench.py --rag hop2rag --limit 50 --retrieval-k 20

# HotpotQA 答案质量测试（注意：在 rag_system/ 目录）
cd tests/rag_system
python bench_hotpotqa_fullwiki.py --rag hop2rag --limit 100
```

---

## 📋 修复检查清单

使用以下清单确认修复是否成功：

- [x] ✅ Python 语法无错误
- [x] ✅ 路径计算正确
- [x] ✅ `write_jsonl` 不再冲突
- [x] ✅ 嵌入模型配置集中化
- [x] ✅ 文档引用正确
- [ ] ⏳ 运行实际测试验证（需要安装依赖）

---

## 🔍 验证修复

### 快速验证
```bash
# 验证语法
python3 -m py_compile Agrag/tests/cores.py \
    Agrag/tests/data/hotpotqa/index_hotpotqa_fullwiki.py \
    Agrag/core/config.py

# 验证路径计算
python3 -c "
from pathlib import Path
f = Path('Agrag/tests/data/hotpotqa/index_hotpotqa_fullwiki.py')
print(f'✅ ROOT = {f.resolve().parents[3]}')
"
```

### 完整验证（需要依赖）
```bash
# 如果已安装依赖，测试导入
cd Agrag
python3 -c "from core.config import EmbeddingConfig; print('✅ 配置导入成功')"
python3 -c "from tests.cores import write_jsonl; print('✅ cores 导入成功')"
```

---

## 💡 常见问题

### Q1: 如何使用自定义的嵌入模型？
```bash
# 设置环境变量
export EMBEDDING_MODEL_PATH="/path/to/your/model"

# 或在 .env 文件中添加
echo 'EMBEDDING_MODEL_PATH="/path/to/your/model"' >> .env
```

### Q2: 如何确认使用了哪个嵌入模型？
运行索引脚本时会显示：
```
✅ Using local embedding model: /mnt/.../BAAI-bge-base-en-v1.5
# 或
⚠️ Local model not found, using HuggingFace Hub: BAAI/bge-base-en-v1.5
```

### Q3: `bench_hotpotqa_fullwiki.py` 在哪里？
```bash
# 在这里：
tests/rag_system/bench_hotpotqa_fullwiki.py

# 不在这里（旧文档中的错误）：
# tests/answer_quality/bench_hotpotqa_fullwiki.py  # ❌ 不存在
```

### Q4: 修复后代码还能在原来的环境运行吗？
✅ **完全向后兼容**！
- 如果本地路径存在，自动使用（与之前相同）
- 新增了环境变量和 fallback 支持
- 不需要修改任何配置即可运行

---

## 📚 文档位置

| 文档 | 位置 |
|------|------|
| 详细检查报告 | `docs/Agrag_tests_检查报告.md` |
| 修复总结 | `docs/修复总结.md` |
| 更新日志 | `docs/CHANGELOG.md` |
| 快速参考 | `docs/快速修复参考.md`（本文档） |

---

## 🎯 下一步

1. **立即做**:
   ```bash
   # 可选：配置环境变量
   export EMBEDDING_MODEL_PATH="/your/path"

   # 验证修复
   cd Agrag
   python3 -m py_compile tests/**/*.py
   ```

2. **运行测试**:
   ```bash
   # 运行快速验证
   cd tests/vllm_baseline
   python test_vllm_baseline.py --context-length 500 --num-requests 5
   ```

3. **查看文档**:
   - 阅读 `docs/修复总结.md` 了解详情
   - 参考 `tests/README.md` 查看更新后的测试指南

---

**修复完成**: ✅ 所有严重和高优先级问题已解决
**代码状态**: ✅ 语法正确，逻辑验证通过
**兼容性**: ✅ 完全向后兼容

---

*生成时间: 2026-01-19*
*工具: Claude Code*
